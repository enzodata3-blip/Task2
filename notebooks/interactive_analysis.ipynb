{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Optimization with Interaction Terms\n",
    "## Human-in-the-Loop Approach to Feature Engineering\n",
    "\n",
    "This notebook demonstrates a systematic approach to improving machine learning models by:\n",
    "1. Analyzing feature correlations\n",
    "2. Engineering interaction terms\n",
    "3. Comparing baseline vs. enhanced models\n",
    "4. Providing human-guided optimization recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_loader import DataLoader\n",
    "from correlation_analyzer import CorrelationAnalyzer\n",
    "from feature_engineer import FeatureEngineer\n",
    "from model_optimizer import ModelOptimizer\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"✓ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load your dataset or use a sample dataset for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = DataLoader()\n",
    "\n",
    "# Option 1: Load your own CSV\n",
    "# data, target = loader.load_csv('../data/your_dataset.csv', 'target_column'), 'target_column'\n",
    "\n",
    "# Option 2: Load sample dataset\n",
    "data, target = loader.load_sample_dataset('diabetes')  # Options: 'diabetes', 'breast_cancer', 'california_housing'\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nDataset Preview:\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data exploration\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nFeature Types:\")\n",
    "print(data.dtypes.value_counts())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum().sum())\n",
    "print(\"\\nTarget Variable Statistics:\")\n",
    "if data[target].dtype in ['object', 'category'] or data[target].nunique() < 20:\n",
    "    print(data[target].value_counts())\n",
    "else:\n",
    "    print(data[target].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation Analysis\n",
    "\n",
    "Analyze feature correlations to understand relationships and identify potential interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize correlation analyzer\n",
    "analyzer = CorrelationAnalyzer(data, target)\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = analyzer.compute_correlations(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation heatmap\n",
    "analyzer.plot_correlation_heatmap(figsize=(14, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target correlations\n",
    "analyzer.plot_target_correlations(top_n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for multicollinearity\n",
    "multicollinearity = analyzer.identify_multicollinearity(threshold=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggest interaction terms\n",
    "suggested_interactions = analyzer.suggest_interaction_terms(\n",
    "    min_correlation=0.15,\n",
    "    max_correlation=0.80,\n",
    "    top_n=15\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "interactions_df = pd.DataFrame([\n",
    "    {\n",
    "        'Feature 1': f1,\n",
    "        'Feature 2': f2,\n",
    "        'Score': score,\n",
    "        'F1 → Target': analyzer.target_correlations[f1],\n",
    "        'F2 → Target': analyzer.target_correlations[f2],\n",
    "        'F1 ↔ F2': analyzer.correlation_matrix.loc[f1, f2]\n",
    "    }\n",
    "    for f1, f2, score in suggested_interactions\n",
    "])\n",
    "\n",
    "print(\"\\nSuggested Interaction Terms:\")\n",
    "interactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Create interaction terms based on correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature engineer\n",
    "engineer = FeatureEngineer(data, target)\n",
    "\n",
    "# Extract top interaction pairs\n",
    "interaction_pairs = [(feat1, feat2) for feat1, feat2, _ in suggested_interactions[:10]]\n",
    "\n",
    "# Create interaction terms\n",
    "data_with_interactions = engineer.create_interaction_terms(\n",
    "    interaction_pairs=interaction_pairs,\n",
    "    interaction_type='multiply'  # Options: 'multiply', 'add', 'divide', 'subtract', 'all'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Create polynomial features for top correlated features\n",
    "top_features = analyzer.target_correlations.head(5).index.tolist()\n",
    "print(f\"Creating polynomial features for: {top_features}\")\n",
    "\n",
    "data_with_interactions = engineer.create_polynomial_features(\n",
    "    features=top_features,\n",
    "    degree=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove low variance features\n",
    "data_with_interactions = engineer.remove_low_variance_features(threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering summary\n",
    "feature_summary = engineer.get_feature_summary()\n",
    "\n",
    "print(f\"\\nNew Features Created: {feature_summary['created_features']}\")\n",
    "print(f\"Feature List:\")\n",
    "for feat in engineer.created_features[:20]:\n",
    "    print(f\"  • {feat}\")\n",
    "if len(engineer.created_features) > 20:\n",
    "    print(f\"  ... and {len(engineer.created_features) - 20} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training: Baseline vs. Enhanced\n",
    "\n",
    "Train two models and compare performance:\n",
    "- **Baseline**: Original features only\n",
    "- **Enhanced**: Original + interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine task type\n",
    "task_type = 'regression' if data[target].nunique() > 20 else 'classification'\n",
    "print(f\"Task Type: {task_type.upper()}\")\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = ModelOptimizer(task_type=task_type, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare baseline data (original features only)\n",
    "original_features = [col for col in data.columns if col != target]\n",
    "baseline_data = data[original_features + [target]].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = optimizer.prepare_data(\n",
    "    baseline_data,\n",
    "    target,\n",
    "    scale_features=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "baseline_model = optimizer.train_baseline_model(\n",
    "    model_type='auto'  # Options: 'auto', 'logistic', 'random_forest', 'gradient_boosting'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline feature importance\n",
    "baseline_importance = optimizer.get_feature_importance(\n",
    "    baseline_model,\n",
    "    X_train.columns.tolist(),\n",
    "    top_n=15\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(baseline_importance)), baseline_importance['importance'], color='steelblue')\n",
    "plt.yticks(range(len(baseline_importance)), baseline_importance['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Baseline Model - Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare enhanced data (with interactions)\n",
    "enhanced_data = data_with_interactions.copy()\n",
    "interaction_feature_names = engineer.created_features\n",
    "\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = optimizer.prepare_data(\n",
    "    enhanced_data,\n",
    "    target,\n",
    "    scale_features=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train enhanced model\n",
    "enhanced_model = optimizer.train_enhanced_model(\n",
    "    baseline_features=original_features,\n",
    "    interaction_features=interaction_feature_names,\n",
    "    model_type='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get enhanced feature importance\n",
    "all_features = [f for f in original_features + interaction_feature_names if f in X_train_enh.columns]\n",
    "enhanced_importance = optimizer.get_feature_importance(\n",
    "    enhanced_model,\n",
    "    all_features,\n",
    "    top_n=15\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['orangered' if '_X_' in f or '_POW' in f else 'steelblue' \n",
    "          for f in enhanced_importance['feature']]\n",
    "plt.barh(range(len(enhanced_importance)), enhanced_importance['importance'], color=colors)\n",
    "plt.yticks(range(len(enhanced_importance)), enhanced_importance['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Enhanced Model - Feature Importance (Orange = Interaction Terms)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "comparison = optimizer.compare_models()\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate improvement\n",
    "if task_type == 'classification':\n",
    "    baseline_score = optimizer.baseline_results['test_accuracy']\n",
    "    enhanced_score = optimizer.enhanced_results['test_accuracy']\n",
    "    metric_name = 'Accuracy'\n",
    "else:\n",
    "    baseline_score = optimizer.baseline_results['test_r2']\n",
    "    enhanced_score = optimizer.enhanced_results['test_r2']\n",
    "    metric_name = 'R² Score'\n",
    "\n",
    "improvement = ((enhanced_score - baseline_score) / baseline_score) * 100\n",
    "\n",
    "# Visualize comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Performance comparison\n",
    "models = ['Baseline', 'Enhanced']\n",
    "scores = [baseline_score, enhanced_score]\n",
    "colors = ['steelblue', 'orangered' if improvement > 0 else 'gray']\n",
    "\n",
    "ax1.bar(models, scores, color=colors, alpha=0.7)\n",
    "ax1.set_ylabel(metric_name)\n",
    "ax1.set_title(f'Model Performance Comparison\\n(Improvement: {improvement:+.2f}%)')\n",
    "ax1.set_ylim([min(scores)*0.95, max(scores)*1.05])\n",
    "for i, v in enumerate(scores):\n",
    "    ax1.text(i, v, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# Feature count comparison\n",
    "n_features = [optimizer.baseline_results['n_features'], optimizer.enhanced_results['n_features']]\n",
    "ax2.bar(models, n_features, color=['steelblue', 'orangered'], alpha=0.7)\n",
    "ax2.set_ylabel('Number of Features')\n",
    "ax2.set_title('Feature Count Comparison')\n",
    "for i, v in enumerate(n_features):\n",
    "    ax2.text(i, v, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PERFORMANCE IMPROVEMENT: {improvement:+.2f}%\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Human-in-the-Loop Recommendations\n",
    "\n",
    "Based on the analysis, here are actionable recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\" \"*25 + \"RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if improvement > 5:\n",
    "    print(\"\\n✓ STRONG IMPROVEMENT detected!\")\n",
    "    print(\"  → Interaction terms are highly beneficial for this problem\")\n",
    "    print(\"  → Consider using the enhanced model in production\")\n",
    "    print(\"  → Explore additional domain-specific interactions\")\n",
    "    print(\"  → Investigate top interaction features for insights\")\n",
    "    \n",
    "elif improvement > 1:\n",
    "    print(\"\\n✓ MODERATE IMPROVEMENT detected\")\n",
    "    print(\"  → Interaction terms provide some benefit\")\n",
    "    print(\"  → Consider feature selection to reduce model complexity\")\n",
    "    print(\"  → Monitor for overfitting using cross-validation\")\n",
    "    print(\"  → Try different model algorithms (XGBoost, LightGBM)\")\n",
    "    \n",
    "elif improvement > -1:\n",
    "    print(\"\\n→ MINIMAL CHANGE\")\n",
    "    print(\"  → Interactions do not add significant value\")\n",
    "    print(\"  → Consider using baseline model for simplicity\")\n",
    "    print(\"  → Explore alternative feature engineering approaches:\")\n",
    "    print(\"     - Domain-specific transformations\")\n",
    "    print(\"     - Temporal features (if time-series data)\")\n",
    "    print(\"     - Feature selection methods\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n⚠ PERFORMANCE DEGRADATION\")\n",
    "    print(\"  → Interaction terms may cause overfitting\")\n",
    "    print(\"  → Recommendations:\")\n",
    "    print(\"     1. Use baseline model\")\n",
    "    print(\"     2. Apply feature selection (remove low-importance interactions)\")\n",
    "    print(\"     3. Use regularization (L1/L2)\")\n",
    "    print(\"     4. Increase training data if available\")\n",
    "    print(\"     5. Try ensemble methods with regularization\")\n",
    "\n",
    "# Identify valuable interaction terms\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"VALUABLE INTERACTION TERMS:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "interaction_features_in_model = [\n",
    "    f for f in interaction_feature_names\n",
    "    if f in enhanced_importance['feature'].values\n",
    "]\n",
    "\n",
    "if interaction_features_in_model:\n",
    "    print(f\"\\nTop {min(5, len(interaction_features_in_model))} interaction features by importance:\")\n",
    "    for i, feat in enumerate(interaction_features_in_model[:5], 1):\n",
    "        if feat in enhanced_importance['feature'].values:\n",
    "            imp = enhanced_importance[enhanced_importance['feature'] == feat]['importance'].values[0]\n",
    "            print(f\"  {i}. {feat}: {imp:.4f}\")\n",
    "else:\n",
    "    print(\"\\nNo interaction terms in top features - interactions may need refinement\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison results\n",
    "comparison.to_csv('../results/model_comparison.csv', index=False)\n",
    "print(\"✓ Comparison results saved\")\n",
    "\n",
    "# Save models\n",
    "optimizer.save_models(\n",
    "    baseline_path='../results/models/baseline_model.joblib',\n",
    "    enhanced_path='../results/models/enhanced_model.joblib'\n",
    ")\n",
    "\n",
    "# Save feature importance\n",
    "baseline_importance.to_csv('../results/baseline_feature_importance.csv', index=False)\n",
    "enhanced_importance.to_csv('../results/enhanced_feature_importance.csv', index=False)\n",
    "print(\"✓ Feature importance saved\")\n",
    "\n",
    "print(\"\\n✓ All results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Experiment with different interaction types** (add, divide, subtract)\n",
    "2. **Try alternative model algorithms** (XGBoost, LightGBM, Neural Networks)\n",
    "3. **Perform cross-validation** for more robust evaluation\n",
    "4. **Feature selection** to reduce model complexity\n",
    "5. **Hyperparameter tuning** for both models\n",
    "6. **Domain-specific feature engineering** based on problem context\n",
    "7. **Deploy best model** to production environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
